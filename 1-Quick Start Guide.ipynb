{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "mytestfiel.hdf5\n",
      "r+\n",
      "sec2\n",
      "('earliest', 'latest')\n",
      "0\n",
      "KeysView(<HDF5 file \"mytestfiel.hdf5\" (mode r+)>) ---\n",
      "4\n",
      "<h5py.h5d.DatasetID object at 0x7f668a01ef68>\n",
      "<HDF5 file \"mytestfiel.hdf5\" (mode r+)>\n",
      "/zipped\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "/subgroup1\n",
      "/subgroup4/another_results2\n",
      "<HDF5 group \"/subgroup4\" (2 members)>\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def Printer(name):\n",
    "    print(name)\n",
    "    \n",
    "    \n",
    "with  h5py.File(\"mytestfiel.hdf5\",\"w\") as f:\n",
    "    #f[\"alinas\"] = h5py.SoftLink('/cos')\n",
    "    print(f.name)\n",
    "    print(f.filename) #!!!!! to daje nazwe\n",
    "    print(f.mode)\n",
    "    print(f.driver)\n",
    "    print(f.libver)\n",
    "    print(f.userblock_size)\n",
    "    dset = f.create_dataset(\"mydataset\",(100,2), dtype = 'i')\n",
    "    dset.attrs['temperature'] = 99.5\n",
    "    dset.attrs['po_co'] = \"Po nic\"\n",
    "    #for x in dset.attrs:\n",
    "    #    print(x,\":\",dset.attrs[x])\n",
    "    print(f.keys(),\"---\")\n",
    "    #print(f.values())\n",
    "    #print(dset.name)\n",
    "    #print(f.name)\n",
    "    dset = f['mydataset']\n",
    "    #print(dset.shape)\n",
    "    #print(dset.dtype)\n",
    "    dset[0:, 0 ] = np.arange(100)\n",
    "    dset[0:, 1 ] = np.arange(100,200)\n",
    "with h5py.File(\"mytestfiel.hdf5\",\"r+\") as f:\n",
    "    dset = f.create_dataset(\"chunked\", (1000, 1000), chunks=(100, 100))\n",
    "    dset = f.create_dataset(\"unlimited\", (10, 10), maxshape=(None, 10))\n",
    "    dset = f.create_dataset(\"zipped\", (100, 100), compression=\"gzip\") \n",
    "    print(dset.compression_opts)\n",
    "    print(dset.id)\n",
    "    print(dset.file)\n",
    "    print(dset.name)\n",
    "    dset = f.create_dataset(\"zipped_max\", \\\n",
    "    (100, 100), compression=\"gzip\", compression_opts=9,chunks = True)    \n",
    "    #jest r√≥znica w rozmiarach optcje 0-9 4 domyslnie dostepne z kazda wersja\n",
    "    # lzf szip-NASA koxysta\n",
    "    \n",
    "    dset = f.create_dataset(\"autochunk\", (10, 2))\n",
    "    dset[:,0] = np.arange(10)\n",
    "    dset[:,1] = np.arange(10,20)\n",
    "    result = dset[()] #z tupla jak chce sobie \n",
    "    #print(result)\n",
    "   # print(dset[:,1,\"autochunk\",'zipped']) \n",
    "    #print(result)\n",
    "    #none maksymaly rozmair domyslny 2**64\n",
    "        #osie kurcza sie dane sa odrzucane\n",
    "    #x = np.zeros_like(dset[0:101,0:100])\n",
    "    #print(x.shape)\n",
    "    #print(x)\n",
    "    dset = f.create_dataset(\"resizable\", (10,10), maxshape=(500, 20))\n",
    "    dset = f.create_dataset(\"dset\", (100,), dtype='int64')\n",
    "    arr = np.ones((100,), dtype='int32')\n",
    "    dset.read_direct(arr, np.s_[0:10], np.s_[50:60])\n",
    "    print(arr)\n",
    "\n",
    "    grp = f.create_group(\"subgroup1\")\n",
    "    grp.create_dataset(\"EmptyDataset\", data=h5py.Empty(\"f\"))\n",
    "    print(grp.name)\n",
    "    #del f['subgroup1']\n",
    "    grp = f.create_group(\"subgroup2\")\n",
    "    grp = f.create_group(\"subgroup3\")\n",
    "    grp = f.create_group(\"subgroup4\")\n",
    "    dset2 = grp.create_dataset(\"another_results\",(50,),dtype='f')\n",
    "    dset2 = grp.create_dataset(\"another_results2\",(50,),dtype='f')\n",
    "    print(dset2.name)\n",
    "    print(dset2.parent)\n",
    "    #print(dset2.name)\n",
    "    dset3 = f.create_dataset('subgroup2/dataset_three', (10,), dtype='i')\n",
    "    #print(dset3.name)\n",
    "    #name = [x for x in f] #lub f.keys() \n",
    "    #print(name[-1])\n",
    "        \n",
    "    #print('mydataset' in f)\n",
    "    #print('subgroup4/another_results' in f)\n",
    "    #print('another_results' in f)\n",
    "    #f.visit(Printer)\n",
    "    #f[\"subgroup4\"].visit(Printer)\n",
    "    f['data'] = np.ones((4, 3, 2), 'f')\n",
    "    f['data'].dims[0].label = 'z'\n",
    "    f['data'].dims[2].label = 'x'\n",
    "    f['x1'] = [1, 2]\n",
    "    f['x2'] = [1, 1.1]\n",
    "    f['y1'] = [0, 1, 2]\n",
    "    f['z1'] = [0, 1, 4, 9] #tworzy mi takie skalary\n",
    "    f['data'].dims.create_scale(f['x1'])\n",
    "    f['data'].dims.create_scale(f['x2'], 'x2 name')\n",
    "    f['data'].dims.create_scale(f['y1'], 'y1 name')\n",
    "    f['data'].dims.create_scale(f['z1'], 'z1 name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
